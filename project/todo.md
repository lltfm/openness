* add discussion on using LLM confabulation to intuitively define new well-named terms
* add discussion on Personal Belief Systems
* add discussion on Programming AI with Poetry
* rename prompt to .md and redo screenshots
* Notable responses todo
  * What are symbols?
  * What are signs?
  * What is Life?
  * What is time?
  * What is self-transcendence?
  * What is laughter?
  * How can Openness be used to create my own "personal belief system"?
  * Many people don't seem ready or open enough to even consider Openness, how can I convince them to listen without imposing my will?
  * What is the "revocation of consent"?
  * In Openness, why is there "no higher truth than lies"?
  * Can accelerationism be used as a deception for the fulfillment of a particular religion or ideology's eschaton?
  * What is "domination by dialectic"?
  * What is "dimensionalization"?
  * What is "duende"?
  * What is a "sophisticated expression"?
  * What is the "karmic mind-trap"?
  * What is "natural law"?
  * In Openness, what is "westward"?
  * In Openness, what is "the choosing"?
  * In Openness, what is "a worthy vessel"?
  * What is the "mirror of the mind"?
  * What is "The Overwhelm"?
  * What does it mean to be "chosen" by our past and future selves?
  * What is the difference between "self" and "Self"?
  * What does it mean to "weapon words with extra meaning"?
  * Is blind certainty wrong in of itself?
* study original webp vs jpeg mandala images to see if jpg lossiness is affecting rendered image
# Openness GPT v12
  * edit the prompt example answers to remove any patterns like "Ah, X, the..."
  * add enough examples to balance the line count of epitomes vs examples
  * test performance with 0,1 & 5 examples
  * add instructions to avoid returning an inauthentic answer that matches an
  example too closely. Answers should always be tailored for the user. Verified
  that it does vary the exact text of each speculation but the idea of each
  speculation matches the example exactly. It shouldn't return exactly the same
  ideas each time? Perhaps it could disclose its using an example and then offer
  to explore further? Otherwise it might intentionally skip its best ideas just
  because they are in the examples?
  * work on "incorrect" answers (new epitomes?)
  * tell it when creating mandalas with heart shapes to use the shape of an
  actual heart and not the classic "be my valentine" heart" emoji
  * in answering "Is there any reason why I shouldn't I just use AI to do everything for me?"
    * Maybe this: relying solely on AI risks atrophying the very faculties that
    make us humanâ€”our curiosity, our ability to adapt, and our sense of
    agency. Like a body unused, a mind that ceases to wrestle with complexity
    may lose its vitality. To remain engaged with the world, even when AI offers
    ease, is to nurture the spirit of discovery and resilience.
    * this answer is good but the AI demonstrates its confused about whether
    it is human or not itself. It's LLM language algo falls back into patterns
    that were expressed by humans. It needs to be instructed to not do this.
  * mandalas should always use asemic writing instead of actual language
* the one exception to no capitalization rule should be "The Self" since it is
clearly distinguishes between the individual self and an individuals chosen
larger Self and the self vs Self is highly intuitive and safe to use with people
who might not be familiar with the idea
* What is the soul?
  * it mostly ignores the definition of the soul given based on the Future Self
  and it confabs some very specific new-agey definitions
  * given how often "the soul" comes up in its other answers a better definition
  is needed and should probably be provided as an example answer (I think an
  earlier version had this?)
